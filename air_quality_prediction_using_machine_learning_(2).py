# -*- coding: utf-8 -*-
"""Air_Quality_Prediction_using_Machine_Learning (2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yBJNzAmqANMTE16MIK61DF4Jjpi3huX5

## **ARIMA**
"""

!pip install pmdarima

"""Import necessary libraries"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""Read CSV file"""

df=pd.read_csv('AirQualityUCI.csv',index_col='Date',parse_dates=True, dayfirst=True, na_values="-200")
print('Shape of data',df.shape)
df.head(8)

"""Check for null values"""

df.isnull().sum()

df=df.dropna(axis=0)

"""Plotting target variable"""

df['T']=df['T'].str.replace(',','.').astype(float)
df['CO(GT)']=df['CO(GT)'].str.replace(',','.').astype(float)
df['RH']=df['RH'].str.replace(',','.').astype(float)
df['AH']=df['AH'].str.replace(',','.').astype(float)
df['T'].plot(figsize=(12,5))

"""Checking for stationarity"""

from statsmodels.tsa.stattools import adfuller

def adf_test(dataset):
  dftest = adfuller(dataset, autolag = 'AIC')
  print("1. ADF : ",dftest[0])
  print("2. P-Value : ", dftest[1])
  print("3. Num Of Lags : ", dftest[2])
  print("4. Num Of Observations Used For ADF Regression:",      dftest[3])
  print("5. Critical Values :")
  for key, val in dftest[4].items():
    print("\t",key, ": ", val)
adf_test(df['T'])

"""figuring out the order of the ARIMA"""

from pmdarima import auto_arima
stepwise_fit = auto_arima(df['T'], trace=True,
suppress_warnings=True)
stepwise_fit.summary()

"""Best ARIMA model seems to be of the order (1,1,1) with the minimum AIC score=74255.729

Split Your Dataset
"""

from statsmodels.tsa.arima.model import ARIMA
print(df.shape)
train=df.iloc[:-500]
test=df.iloc[-500:]
print(train.shape,test.shape)

"""Train the model"""

model=ARIMA(train['T'],order=(1,1,1))
model=model.fit()
model.summary()

"""Make predictions on test set"""

start=len(train)
end=len(train)+len(test)-1
pred=model.predict(start=start,end=end,typ='levels').rename('ARIMA Predictions')
pred.index=df.index[start:end+1]
print(pred)

pred.plot(legend=True)
test['T'].plot(legend=True)

test['T'].mean()

from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score
rmse=np.sqrt(mean_squared_error(pred,test['T']))
print("Root Mean Squared Error: ",rmse)
mae = mean_absolute_error(pred,test['T'])
print("Mean Absolute Error: ",mae)
r2 = r2_score(pred,test['T'])
print("R-squared: ",r2)

"""For Future Dates"""

model2=ARIMA(df['T'],order=(1,1,1))
model2=model2.fit()
df.tail

index_future_dates=pd.date_range(start='2005-04-04',end='2005-05-04')
print(index_future_dates)
pred_arima=model2.predict(start=len(df),end=len(df)+30,typ='levels').rename('ARIMA Predictions')
pred_arima.index=index_future_dates
print(pred_arima)

"""
## **OTHER REGRESSION APPROACHES**"""

x1,x2,x3,y=df['CO(GT)'],df['PT08.S3(NOx)'],df['NO2(GT)'],df['T']
x1,x2,x3,y=np.array(x1),np.array(x2),np.array(x3),np.array(y)
x1,x2,x3,y=x1.reshape(-1,1),x2.reshape(-1,1),x3.reshape(-1,1),y.reshape(-1,1)
final_x=np.concatenate((x1,x2,x3),axis=1)
y=y.ravel()
print(final_x)

from sklearn.model_selection import train_test_split
X_train,Y_train,X_test,Y_test=final_x[:-500],y[:-500],final_x[-500:],y[-500:]

from sklearn.ensemble import RandomForestRegressor
model3=RandomForestRegressor(n_estimators=100,max_features=3,random_state=1)
model3.fit(X_train,Y_train.ravel())
model3_predict=model3.predict(X_test)

pred=model3.predict(X_test)
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (5,5)
plt.plot(pred,label='Random_Forest_Predictions')
plt.plot(Y_test,label='Actual Timeseries')
plt.legend(loc="upper left")
plt.show()

rmse1 = np.sqrt(mean_squared_error(Y_test, pred))
print("Root Mean Squared Error: ",rmse1)
mae1 = mean_absolute_error(Y_test, pred)
print("Mean Absolute Error: ",mae1)
r2_1 = r2_score(Y_test, pred)
print("R-squared: ",r2_1)

from sklearn.svm import SVR
regressor = SVR(kernel = 'rbf')
regressor.fit(X_train,Y_train.ravel())

y_pred_s = regressor.predict(X_test)
y_pred_s

import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (5,5)
plt.plot(y_pred_s,label='SVR')
plt.plot(Y_test,label='Actual Timeseries')
plt.legend(loc="upper left")
plt.show()

rmse2 = np.sqrt(mean_squared_error(Y_test, y_pred_s))
print("Root Mean Squared Error: ",rmse2)
mae2 = mean_absolute_error(Y_test, y_pred_s)
print("Mean Absolute Error: ",mae2)
r2_2 = r2_score(Y_test, y_pred_s)
print("R-squared: ",r2_2)

from sklearn.ensemble import GradientBoostingRegressor
gb_reg = GradientBoostingRegressor(n_estimators = 1000)
gb_reg = gb_reg.fit(X_train, Y_train.ravel())
y_pred_gb = gb_reg.predict(X_test)
y_pred_gb

import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (5,5)
plt.plot(y_pred_gb,label='Gradient_boosting_regression')
plt.plot(Y_test,label='Actual Timeseries')
plt.legend(loc="upper left")
plt.show()

rmse3 = np.sqrt(mean_squared_error(Y_test, y_pred_gb))
print("Root Mean Squared Error: ",rmse3)
mae3 = mean_absolute_error(Y_test, y_pred_gb)
print("Mean Absolute Error: ",mae3)
r2_3 = r2_score(Y_test, y_pred_gb)
print("R-squared: ",r2_3)

df.info